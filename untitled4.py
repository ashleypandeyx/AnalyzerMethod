# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KDLUXWq9nITSMw-xiFXvw-Wt4ro5tqcQ
"""

!pip install mediapipe opencv-python-headless google-cloud-storage
!pip3 install --upgrade --user --quiet google-cloud-aiplatform
!apt-get install -y ffmpeg

import cv2
from google.cloud import storage
import numpy as np
import math
import mediapipe as mp

# Step 3: Authenticate your Notebook Environment (if using Google Colab)
from google.colab import auth
auth.authenticate_user()

PROJECT_ID = "workoutapp-616d04]"
LOCATION = "us-central1"

import vertexai
vertexai.init(project=PROJECT_ID, location=LOCATION)

from vertexai.preview.generative_models import GenerativeModel, SafetySetting
from google.colab import auth
auth.authenticate_user()

from IPython.display import display
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

from vertexai.generative_models import (
    GenerationConfig,
    GenerativeModel,
    HarmBlockThreshold,
    HarmCategory,
    Part,
)

# Step 5: Import Necessary Libraries
from IPython.display import display
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

from google.cloud import storage, aiplatform
from google.cloud.aiplatform.gapic.schema import predict
from math import degrees, atan2

import base64

# Landmark indices mapped to human-readable names
LANDMARK_NAMES = {
    0: "NOSE",
    11: "LEFT_SHOULDER",
    12: "RIGHT_SHOULDER",
    23: "LEFT_HIP",
    24: "RIGHT_HIP",
    25: "LEFT_KNEE",
    26: "RIGHT_KNEE",
    27: "LEFT_ANKLE",
    28: "RIGHT_ANKLE",
    # Add other landmarks as necessary
}


# Step 1: Download video from Google Cloud Storage
def download_blob(bucket_name, source_blob_name, destination_file_name):
    """Downloads a blob from the bucket."""
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(source_blob_name)
    blob.download_to_filename(destination_file_name)
    print(f"Blob {source_blob_name} downloaded to {destination_file_name}.")


# Step 2: Extract keypoints from video using MediaPipe
def extract_keypoints(video_path):
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)
    cap = cv2.VideoCapture(video_path)
    keypoints_list = []


    if not cap.isOpened():
        print("Error: Could not open video.")
        return keypoints_list


    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break


        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)
        if results.pose_landmarks:
            keypoints = {LANDMARK_NAMES[i]: (lm.x, lm.y, lm.z) for i, lm in enumerate(results.pose_landmarks.landmark) if i in LANDMARK_NAMES}
            keypoints_list.append((frame, keypoints))


    cap.release()
    print("Keypoint extraction completed.")
    return keypoints_list


# Function to calculate angle between three points with a sanity check
def calculate_angle(a, b, c):
    from math import degrees, atan2, pi

    # Calculate angle
    angle = degrees(atan2(c[1] - b[1], c[0] - b[0]) - atan2(a[1] - b[1], a[0] - b[0]))

    # Normalize the angle to the range [0, 360]
    angle = angle % 360

    # If angle is greater than 180, adjust it to make sure it's the smallest angle
    if angle > 180:
        angle = 360 - angle

    # Return the absolute value of the angle
    return abs(angle)


# Step 3: Identify the peak frame based on the workout type
def find_peak_frame(keypoints_list, workout_type):
    peak_frame = None
    peak_keypoints = None
    peak_measure = None


    for frame, keypoints in keypoints_list:
        if workout_type == "squat" or workout_type == "bulgarian_split_squat":
            # Find the lowest hip position
            left_hip_y = keypoints['LEFT_HIP'][1]
            right_hip_y = keypoints['RIGHT_HIP'][1]
            hip_y = max(left_hip_y, right_hip_y)


            if peak_measure is None or hip_y > peak_measure:
                peak_measure = hip_y
                peak_frame = frame
                peak_keypoints = keypoints


        elif workout_type == "rdl" or workout_type == "deadlift":
            # Find the highest hip position (hip extension)
            left_hip_y = keypoints['LEFT_HIP'][1]
            right_hip_y = keypoints['RIGHT_HIP'][1]
            hip_y = min(left_hip_y, right_hip_y)


            if peak_measure is None or hip_y < peak_measure:
                peak_measure = hip_y
                peak_frame = frame
                peak_keypoints = keypoints


        elif workout_type == "hip_thrust":
            # Find the highest hip position during hip thrust
            left_hip_y = keypoints['LEFT_HIP'][1]
            right_hip_y = keypoints['RIGHT_HIP'][1]
            hip_y = min(left_hip_y, right_hip_y)


            if peak_measure is None or hip_y < peak_measure:
                peak_measure = hip_y
                peak_frame = frame
                peak_keypoints = keypoints


        elif workout_type == "bench_press":
            # Find the lowest shoulder position (bar at chest level)
            left_shoulder_y = keypoints['LEFT_SHOULDER'][1]
            right_shoulder_y = keypoints['RIGHT_SHOULDER'][1]
            shoulder_y = max(left_shoulder_y, right_shoulder_y)


            if peak_measure is None or shoulder_y > peak_measure:
                peak_measure = shoulder_y
                peak_frame = frame
                peak_keypoints = keypoints


        elif workout_type == "rows":
            # Find the lowest shoulder position (similar to bench press logic)
            left_shoulder_y = keypoints['LEFT_SHOULDER'][1]
            right_shoulder_y = keypoints['RIGHT_SHOULDER'][1]
            shoulder_y = max(left_shoulder_y, right_shoulder_y)


            if peak_measure is None or shoulder_y > peak_measure:
                peak_measure = shoulder_y
                peak_frame = frame
                peak_keypoints = keypoints


    return peak_frame, peak_keypoints


# Analyze keypoints with Gemini at the peak position
def analyze_with_gemini(peak_frame, peak_keypoints, workout_type):
    vertexai.init(project="workoutapp-616d04", location="us-central1")
    model = GenerativeModel("gemini-1.5-flash-001")

    # Correct angle calculations using the verified calculate_angle function
    hip_angle = calculate_angle(peak_keypoints['LEFT_SHOULDER'], peak_keypoints['LEFT_HIP'], peak_keypoints['LEFT_KNEE'])
    knee_angle = calculate_angle(peak_keypoints['LEFT_HIP'], peak_keypoints['LEFT_KNEE'], peak_keypoints['LEFT_ANKLE'])
    shoulder_angle = calculate_angle(peak_keypoints['RIGHT_SHOULDER'], peak_keypoints['LEFT_SHOULDER'], peak_keypoints['LEFT_HIP'])

    # Construct the prompt for Gemini
    prompt = (
        f"The user is performing a {workout_type} exercise. The angles measured at the peak position are as follows:\n"
        f"- Hip angle: {hip_angle:.2f} degrees\n"
        f"- Knee angle: {knee_angle:.2f} degrees\n"
        f"- Shoulder angle: {shoulder_angle:.2f} degrees\n"
        "This data was recorded during the peak phase of the movement. The user is an intermediate lifter. "
        "Based on this information, please analyze the form and provide CONCISE feedback on whether "
        "these angles are appropriate and how the user can improve their form. Make the response formatted properly and dont write the sentence attaching a video would help"
    )

    response = model.generate_content(
        prompt,
        generation_config=generation_config,
        safety_settings=safety_settings,
        stream=False,
    )

    feedback = response.text if response.text else "No feedback received."

    return feedback, peak_frame, peak_keypoints


# Step 5: Save the frame with incorrect form, display it, and upload to Google Cloud Storage
def save_incorrect_frame(frame, keypoints, save_path, bucket_name, destination_blob_name):
    for keypoint in keypoints.values():
        x, y, _ = keypoint
        cv2.circle(frame, (int(x * frame.shape[1]), int(y * frame.shape[0])), 5, (0, 0, 255), -1)
    cv2.imwrite(save_path, frame)
    print(f"Saved incorrect form frame to {save_path}.")


    # Upload the image back to the bucket
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)
    blob.upload_from_filename(save_path)
    print(f"Uploaded {save_path} to {destination_blob_name} in {bucket_name} bucket.")


# Step 6: Main function to run the full process
def main(video_path, workout_type, bucket_name):
    print("Running main function...")


    # Download video from Google Cloud Storage
    destination_file_name = "local_video.mp4"
    download_blob(bucket_name, video_path, destination_file_name)


    print("Starting keypoint extraction...")
    keypoints_list = extract_keypoints(destination_file_name)


    if not keypoints_list:
        print("No keypoints were extracted. Check the video path or content.")
        return


    # Find the peak frame
    print("Finding the peak frame...")
    peak_frame, peak_keypoints = find_peak_frame(keypoints_list, workout_type)


    if peak_frame is None or peak_keypoints is None:
        print("No peak frame detected. Unable to analyze form.")
        return


    # Analyze with Gemini
    print("Analyzing with Gemini...")
    feedback, incorrect_frame, incorrect_keypoints = analyze_with_gemini(peak_frame, peak_keypoints, workout_type)


    # Save the frame with incorrect form and upload it back to the bucket
    save_path = "incorrect_frame_0.png"
    save_incorrect_frame(incorrect_frame, incorrect_keypoints, save_path, bucket_name, "incorrect_frame_0.png")


    print("Feedback:")
    print(feedback)


# Configuration for Gemini API
generation_config = {
    "max_output_tokens": 8192,
    "temperature": 1,
    "top_p": 0.95,
}


safety_settings = [
    SafetySetting(
        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
    ),
    SafetySetting(
        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
    ),
    SafetySetting(
        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
    ),
    SafetySetting(
        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,
        threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
    ),
]


# Example usage
main("RDL.mp4", "rdl", "video-bucket333")

